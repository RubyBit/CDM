{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aMU344OHhk5D"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from inspect import isfunction\n",
        "from functools import partial\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "#from einops import rearrange\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/g2archie/UNet-MRI-Reconstruction\n",
        "#https://amaarora.github.io/2020/09/13/unet.html#understanding-input-and-output-shapes-in-u-net"
      ],
      "metadata": {
        "id": "rJJnzepW8V8h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "        self.relu  = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.relu(self.conv2(self.relu(self.conv1(x))))"
      ],
      "metadata": {
        "id": "Z05n8evCoj_0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_block = Block(1, 64)\n",
        "x         = torch.randn(1, 1, 28, 28)\n",
        "enc_block(x).shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uCmG6Z_ol6z",
        "outputId": "4387d7ce-c7c6-490a-830b-b7bcc6f978da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, chs=(1,32,64,128,256)):\n",
        "        super().__init__()\n",
        "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
        "        self.pool       = nn.MaxPool2d(2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ftrs = []\n",
        "        for block in self.enc_blocks:\n",
        "            x = block(x)\n",
        "            ftrs.append(x)\n",
        "            x = self.pool(x)\n",
        "        return ftrs"
      ],
      "metadata": {
        "id": "iHMVsckgoejc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chs=(1,32,64,128,256)\n",
        "nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToF3F2kP27To",
        "outputId": "a602ec82-021a-4003-f689-5e529143463a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): Block(\n",
              "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (relu): ReLU()\n",
              "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (1): Block(\n",
              "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (relu): ReLU()\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (2): Block(\n",
              "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (relu): ReLU()\n",
              "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (3): Block(\n",
              "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (relu): ReLU()\n",
              "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder()\n",
        "# input image\n",
        "x    = torch.randn(1, 1, 256, 256)\n",
        "ftrs = encoder(x)\n",
        "for ftr in ftrs: print(ftr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG3chmc9q_Eb",
        "outputId": "e4b8a28a-c88f-4d86-abc0-5806243f5a6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 256, 256])\n",
            "torch.Size([1, 64, 128, 128])\n",
            "torch.Size([1, 128, 64, 64])\n",
            "torch.Size([1, 256, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, chs=(256, 128, 64, 32)):\n",
        "        super().__init__()\n",
        "        self.chs         = chs\n",
        "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
        "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n",
        "        \n",
        "    def forward(self, x, encoder_features):\n",
        "        for i in range(len(self.chs)-1):\n",
        "            x        = self.upconvs[i](x)\n",
        "            enc_ftrs = self.crop(encoder_features[i], x)\n",
        "            x        = torch.cat([x, enc_ftrs], dim=1)\n",
        "            x        = self.dec_blocks[i](x)\n",
        "        return x\n",
        "    \n",
        "    def crop(self, enc_ftrs, x):\n",
        "        _, _, H, W = x.shape\n",
        "        enc_ftrs   = torchvision.transforms.CenterCrop([H, W])(enc_ftrs)\n",
        "        return enc_ftrs"
      ],
      "metadata": {
        "id": "RzVrFvLKrDNn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chs=(1024, 512, 256, 128, 64)\n",
        "nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2bng6y__EQE",
        "outputId": "c5cdfb57-b765-4096-915e-e394086ff7b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (1): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (3): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder()\n",
        "x = torch.randn(1, 256, 28, 28)\n",
        "decoder(x, ftrs[::-1][1:]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X3jtew2tbco",
        "outputId": "e5125b14-4358-4091-bb0c-1c003b301815"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self, enc_chs=(1,32,64,128,256), dec_chs=(256, 128, 64, 32), num_class=1, retain_dim=False, out_sz=(572,572)):\n",
        "      super().__init__()\n",
        "      self.encoder     = Encoder(enc_chs)\n",
        "      self.decoder     = Decoder(dec_chs)\n",
        "      self.head        = nn.Conv2d(dec_chs[-1], num_class, 1)\n",
        "      self.retain_dim  = retain_dim\n",
        "\n",
        "  def forward(self, x):\n",
        "      enc_ftrs = self.encoder(x)\n",
        "      out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
        "      out      = self.head(out)\n",
        "      if self.retain_dim:\n",
        "          out = F.interpolate(out, out_sz)\n",
        "      return out"
      ],
      "metadata": {
        "id": "stsXUxpwvH8Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYU_5HgbBXKX",
        "outputId": "9d13f9db-5d25-47a4-ba70-737a3b6a8348"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchsummary\n",
        "from torchsummary import summary\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
        "model = UNet().to(device)\n",
        "\n",
        "summary(model, (1, 128, 128))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kgGcnyOAwUB",
        "outputId": "0a2591e7-a01c-4407-cc44-cc10a74b0895"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 128, 128]             320\n",
            "              ReLU-2         [-1, 32, 128, 128]               0\n",
            "            Conv2d-3         [-1, 32, 128, 128]           9,248\n",
            "              ReLU-4         [-1, 32, 128, 128]               0\n",
            "             Block-5         [-1, 32, 128, 128]               0\n",
            "         MaxPool2d-6           [-1, 32, 64, 64]               0\n",
            "            Conv2d-7           [-1, 64, 64, 64]          18,496\n",
            "              ReLU-8           [-1, 64, 64, 64]               0\n",
            "            Conv2d-9           [-1, 64, 64, 64]          36,928\n",
            "             ReLU-10           [-1, 64, 64, 64]               0\n",
            "            Block-11           [-1, 64, 64, 64]               0\n",
            "        MaxPool2d-12           [-1, 64, 32, 32]               0\n",
            "           Conv2d-13          [-1, 128, 32, 32]          73,856\n",
            "             ReLU-14          [-1, 128, 32, 32]               0\n",
            "           Conv2d-15          [-1, 128, 32, 32]         147,584\n",
            "             ReLU-16          [-1, 128, 32, 32]               0\n",
            "            Block-17          [-1, 128, 32, 32]               0\n",
            "        MaxPool2d-18          [-1, 128, 16, 16]               0\n",
            "           Conv2d-19          [-1, 256, 16, 16]         295,168\n",
            "             ReLU-20          [-1, 256, 16, 16]               0\n",
            "           Conv2d-21          [-1, 256, 16, 16]         590,080\n",
            "             ReLU-22          [-1, 256, 16, 16]               0\n",
            "            Block-23          [-1, 256, 16, 16]               0\n",
            "        MaxPool2d-24            [-1, 256, 8, 8]               0\n",
            "          Encoder-25  [[-1, 32, 128, 128], [-1, 64, 64, 64], [-1, 128, 32, 32], [-1, 256, 16, 16]]               0\n",
            "  ConvTranspose2d-26          [-1, 128, 32, 32]         131,200\n",
            "           Conv2d-27          [-1, 128, 32, 32]         295,040\n",
            "             ReLU-28          [-1, 128, 32, 32]               0\n",
            "           Conv2d-29          [-1, 128, 32, 32]         147,584\n",
            "             ReLU-30          [-1, 128, 32, 32]               0\n",
            "            Block-31          [-1, 128, 32, 32]               0\n",
            "  ConvTranspose2d-32           [-1, 64, 64, 64]          32,832\n",
            "           Conv2d-33           [-1, 64, 64, 64]          73,792\n",
            "             ReLU-34           [-1, 64, 64, 64]               0\n",
            "           Conv2d-35           [-1, 64, 64, 64]          36,928\n",
            "             ReLU-36           [-1, 64, 64, 64]               0\n",
            "            Block-37           [-1, 64, 64, 64]               0\n",
            "  ConvTranspose2d-38         [-1, 32, 128, 128]           8,224\n",
            "           Conv2d-39         [-1, 32, 128, 128]          18,464\n",
            "             ReLU-40         [-1, 32, 128, 128]               0\n",
            "           Conv2d-41         [-1, 32, 128, 128]           9,248\n",
            "             ReLU-42         [-1, 32, 128, 128]               0\n",
            "            Block-43         [-1, 32, 128, 128]               0\n",
            "          Decoder-44         [-1, 32, 128, 128]               0\n",
            "           Conv2d-45          [-1, 1, 128, 128]              33\n",
            "================================================================\n",
            "Total params: 1,925,025\n",
            "Trainable params: 1,925,025\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 85.50\n",
            "Params size (MB): 7.34\n",
            "Estimated Total Size (MB): 92.91\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unet = UNet()\n",
        "x    = torch.randn(1, 1, 256, 256)\n",
        "unet(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoKKfamr-VUr",
        "outputId": "c2625149-43df-46f8-baf0-ed9060f1cccd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}