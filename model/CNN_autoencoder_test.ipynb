{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYU_5HgbBXKX",
    "outputId": "9d13f9db-5d25-47a4-ba70-737a3b6a8348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.20.1)\n",
      "Requirement already satisfied: torch==1.13.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.13.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2020.12.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from inspect import isfunction\n",
    "from functools import partial\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "#from einops import rearrange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "\tdef __init__(self, encoded_space_dim):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\t### Convolutional section\n",
    "\t\tself.encoder_cnn = nn.Sequential(\n",
    "\t\tnn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "\t\tnn.ReLU(True),\n",
    "\t\tnn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "\t\tnn.BatchNorm2d(16),\n",
    "\t\tnn.ReLU(True),\n",
    "\t\tnn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "\t\tnn.ReLU(True)\n",
    "\t\t)\n",
    "\n",
    "\t\t### Flatten layer\n",
    "\t\tself.flatten = nn.Flatten(start_dim=1)\n",
    "### Linear section\n",
    "\t\tself.encoder_lin = nn.Sequential(\n",
    "\t\t\tnn.Linear(3 * 3 * 32, 128),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.Linear(128, encoded_space_dim)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.encoder_cnn(x)\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tx = self.encoder_lin(x)\n",
    "\t\treturn x\n",
    "\t#output is of dimension (1, encoded_space_dim)\n",
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self, encoded_space_dim):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.decoder_lin = nn.Sequential(\n",
    "\t\t\tnn.Linear(encoded_space_dim, 128),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.Linear(128, 3 * 3 * 32),\n",
    "\t\t\tnn.ReLU(True)\n",
    "\t\t)\n",
    "\n",
    "\t\tself.unflatten = nn.Unflatten(dim=1,\n",
    "\t\tunflattened_size=(32, 3, 3))\n",
    "\n",
    "\t\tself.decoder_conv = nn.Sequential(\n",
    "\t\t\tnn.ConvTranspose2d(32, 16, 3,\n",
    "\t\t\tstride=2, output_padding=0),\n",
    "\t\t\tnn.BatchNorm2d(16),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.ConvTranspose2d(16, 8, 3, stride=2,\n",
    "\t\t\tpadding=1, output_padding=1),\n",
    "\t\t\tnn.BatchNorm2d(8),\n",
    "\t\t\tnn.ReLU(True),\n",
    "\t\t\tnn.ConvTranspose2d(8, 1, 3, stride=2,\n",
    "\t\t\tpadding=1, output_padding=1)\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.decoder_lin(x)\n",
    "\t\tx = self.unflatten(x)\n",
    "\t\tx = self.decoder_conv(x)\n",
    "\t\tx = torch.sigmoid(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_input_channels : int,\n",
    "                 base_channel_size : int,\n",
    "                 latent_dim : int,\n",
    "                 act_fn : object = nn.GELU):\n",
    "\n",
    "        super().__init__()\n",
    "        c_hid = base_channel_size\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(num_input_channels, c_hid, kernel_size=3, padding=1, stride=2), \n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_hid, c_hid, kernel_size=3, padding=1),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_hid, 2*c_hid, kernel_size=3, padding=1, stride=2), \n",
    "            act_fn(),\n",
    "            nn.Conv2d(2*c_hid, 2*c_hid, kernel_size=3, padding=1),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(2*c_hid, 2*c_hid, kernel_size=3, padding=1, stride=2),\n",
    "            act_fn(),\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(2*16*c_hid, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_input_channels : int,\n",
    "                 base_channel_size : int,\n",
    "                 latent_dim : int,\n",
    "                 act_fn : object = nn.GELU):\n",
    "\n",
    "        super().__init__()\n",
    "        c_hid = base_channel_size\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 2*16*c_hid),\n",
    "            act_fn()\n",
    "        )\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2*c_hid, 2*c_hid, kernel_size=3, output_padding=1, padding=1, stride=2),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(2*c_hid, 2*c_hid, kernel_size=3, padding=1),\n",
    "            act_fn(),\n",
    "            nn.ConvTranspose2d(2*c_hid, c_hid, kernel_size=3, output_padding=1, padding=1, stride=2), \n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_hid, c_hid, kernel_size=3, padding=0),\n",
    "            act_fn(),\n",
    "            nn.ConvTranspose2d(c_hid, num_input_channels, kernel_size=3, output_padding=1, padding=1, stride=2),\n",
    "            nn.Tanh() \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = x.reshape(x.shape[0], -1, 4, 4)\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 128])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = Encoder(1, 256,128)\n",
    "x        = torch.randn(1000, 1, 28, 28)\n",
    "enc(x).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, num_blocks=4, num_layers=4, num_filters=64, kernel_size=3, stride=1, padding=1,\n",
    "                 dilation=1, groups=1, bias=True, padding_mode='zeros', activation=nn.ReLU, norm=nn.BatchNorm2d,\n",
    "                 dropout=nn.Dropout2d, residual=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        self.activation = activation\n",
    "        self.norm = norm\n",
    "        self.dropout = dropout\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.num_blocks = num_blocks\n",
    "        self.num_layers = num_layers\n",
    "        self.num_filters = num_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        self.bias = bias\n",
    "        self.padding_mode = padding_mode\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "        self.blocks = nn.ModuleList([self._make_block() for _ in range(self.num_blocks)])\n",
    "        self.head = nn.Conv2d(self.num_filters, self.out_ch, 1)\n",
    "\n",
    "    def _make_block(self):\n",
    "        layers = []\n",
    "        for _ in range(self.num_layers):\n",
    "            layers.append(nn.Conv2d(self.in_ch, self.num_filters, self.kernel_size, self.stride, self.padding,\n",
    "                                    self.dilation, self.groups, self.bias, self.padding_mode))\n",
    "            if self.norm is not None:\n",
    "                layers.append(self.norm(self.num_filters))\n",
    "            if self.activation is not None:\n",
    "                layers.append(self.activation())\n",
    "            if self.dropout is not None:\n",
    "                layers.append(self.dropout())\n",
    "            self.in_ch = self.num_filters\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, cond=None):\n",
    "        for block in self.blocks:\n",
    "            res = x\n",
    "            x = block(x)\n",
    "            if cond is not None:\n",
    "                x += nn.Linear(cond.shape[1], x.shape[1], bias=False)(cond)\n",
    "            if self.residual:\n",
    "                x = x + res\n",
    "        return self.head(x)\n",
    "\n",
    "\n",
    "# Score neural network for the diffusion process. Approximates what you should do at each timestep\n",
    "class ScoreNet(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim, embedding_dim, n_blocks=32):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.resnet = ResNet(self.latent_dim, self.latent_dim, num_blocks=n_blocks, num_layers=4,\n",
    "                             num_filters=64, kernel_size=1, stride=1, padding=1, dilation=1, groups=1, bias=True,\n",
    "                             padding_mode='zeros', activation=nn.ReLU, norm=nn.BatchNorm2d, dropout=nn.Dropout2d,\n",
    "                             residual=True)\n",
    "\n",
    "    def forward(self, x, t, conditioning):\n",
    "        \n",
    "        timestep = get_timestep_embedding(t, self.embedding_dim)\n",
    "        print(\"Timstep dim {}, Cond dim {}\",timestep.shape,  conditioning.shape)\n",
    "        cond = torch.cat([timestep, conditioning], dim=1)\n",
    "        #cond=nn.Flatten(0)(cond)\n",
    "        print(\"Input to liearn\",cond.shape)\n",
    "        \n",
    "        cond = nn.SiLU()(nn.Linear(288, self.embedding_dim * 4)(cond))\n",
    "        cond = nn.SiLU()(nn.Linear(self.embedding_dim * 4, self.embedding_dim * 4)(cond))\n",
    "        cond = nn.Linear(self.embedding_dim * 4, self.embedding_dim)(cond)\n",
    "        print(x.shape)\n",
    "        #x=nn.Flatten(0)(x)\n",
    "        print(x.shape)\n",
    "        h = nn.Linear(self.latent_dim, self.embedding_dim)(x)\n",
    "        h = self.resnet(h, cond)\n",
    "        return x + h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cond=nn.rand()\n",
    "cond=nn.Flatten()(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestep_embedding(timesteps, embedding_dim):\n",
    "    assert len(timesteps.shape) == 1\n",
    "    timesteps *= 1000\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = np.log(10000) / (half_dim - 1)\n",
    "    emb = np.exp(np.arange(half_dim) * -emb)\n",
    "    emb = np.outer(timesteps, emb)\n",
    "    emb = np.concatenate([np.sin(emb), np.cos(emb)], axis=1)\n",
    "    print(timesteps.shape, embedding_dim)\n",
    "    assert emb.shape == (timesteps.shape[0], embedding_dim)\n",
    "    return torch.from_numpy(emb).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,) 32\n",
      "Timstep dim {}, Cond dim {} torch.Size([128, 32]) torch.Size([128, 256])\n",
      "Input to liearn torch.Size([128, 288])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 32]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-42-c2c5361a4368>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m=\u001B[0m \u001B[0mg_t\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mones\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m \u001B[0mscorenet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mconditioning\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-38-1c92c6d9f6d0>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x, t, conditioning)\u001B[0m\n\u001B[0;32m     77\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     78\u001B[0m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlatent_dim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding_dim\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 79\u001B[1;33m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresnet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcond\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     80\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mx\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mh\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-38-1c92c6d9f6d0>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x, cond)\u001B[0m\n\u001B[0;32m     42\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mblock\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mblocks\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m             \u001B[0mres\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m             \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblock\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mcond\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m                 \u001B[0mx\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcond\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcond\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 204\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    205\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    461\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    462\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 463\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    464\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    465\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    457\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    458\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[1;32m--> 459\u001B[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0m\u001B[0;32m    460\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[0;32m    461\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 32]"
     ]
    }
   ],
   "source": [
    "# Testing whole scorenet\n",
    "Time=4\n",
    "def gamma(ts, gamma_min=-6, gamma_max=6):\n",
    "    return gamma_max + (gamma_min - gamma_max) * ts\n",
    "g_t = gamma(Time)\n",
    "embed=256\n",
    "conditioning = torch.arange(128) % (10 + 26 + 26 + 1)\n",
    "conditioning=torch.nn.Embedding( num_embeddings=128,embedding_dim=embed)(conditioning)\n",
    "scorenet = ScoreNet(latent_dim=128,embedding_dim=32)\n",
    "x        = torch.randn(1,128)\n",
    "#setting the t to be a vector\n",
    "t= g_t * np.ones(x.shape[1])\n",
    "\n",
    "scorenet(x,t,conditioning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing dimension match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,) 32\n",
      "torch.Size([128, 32]) torch.Size([128, 32])\n"
     ]
    }
   ],
   "source": [
    "# Stesting get_timestep_embedding\n",
    "Time=4\n",
    "def gamma(ts, gamma_min=-6, gamma_max=6):\n",
    "    return gamma_max + (gamma_min - gamma_max) * ts\n",
    "g_t = gamma(Time)\n",
    "\n",
    "\n",
    "#Dimneison of conditioning must be same as th second dimenison of the x in this case\n",
    "conditioning = torch.arange(128) % (10 + 26 + 26 + 1)\n",
    "conditioning=torch.nn.Embedding( num_embeddings=10 + 26 + 26 + 1,embedding_dim=32)(conditioning)\n",
    "scorenet = ScoreNet(latent_dim=128,embedding_dim=128)\n",
    "x        = torch.randn(1,128)#encoder output\n",
    "\n",
    "#Setting the t to be a vector\n",
    "t= g_t * np.ones(x.shape[1])\n",
    "timestep=get_timestep_embedding(t, 32)\n",
    "print(timestep.shape,  conditioning.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditioning = torch.arange(256) % (10 + 26 + 26 + 1)\n",
    "conditioning=torch.nn.Embedding( num_embeddings=10 + 26 + 26 + 1,embedding_dim=128)(conditioning)\n",
    "conditioning.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond       = torch.randn(10,128)\n",
    "cond=nn.Flatten(0)(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,) 128\n",
      "Timstep dim {}, Cond dim {} torch.Size([128, 128]) torch.Size([128, 256])\n",
      "Input to liearn torch.Size([49152])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x128 and 49152x128)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-76-123526ba6d44>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m=\u001B[0m \u001B[0mg_t\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mones\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m \u001B[0mscorenet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mconditioning\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-62-73c5916ddf66>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x, t, conditioning)\u001B[0m\n\u001B[0;32m     74\u001B[0m         \u001B[0mcond\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding_dim\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding_dim\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcond\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m         \u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mFlatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 76\u001B[1;33m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlatent_dim\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membedding_dim\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     77\u001B[0m         \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresnet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcond\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     78\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mx\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mh\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1192\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1195\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1196\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    113\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 114\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    115\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    116\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (1x128 and 49152x128)"
     ]
    }
   ],
   "source": [
    "# Testing whole scorenet\n",
    "Time=4\n",
    "def gamma(ts, gamma_min=-6, gamma_max=6):\n",
    "    return gamma_max + (gamma_min - gamma_max) * ts\n",
    "g_t = gamma(Time)\n",
    "embed=256\n",
    "latent=49152\n",
    "conditioning = torch.arange(128) % (10 + 26 + 26 + 1)\n",
    "conditioning=torch.nn.Embedding( num_embeddings=128,embedding_dim=embed)(conditioning)\n",
    "scorenet = ScoreNet(latent_dim=latent,embedding_dim=128)\n",
    "x        = torch.randn(1,128)\n",
    "#setting the t to be a vector\n",
    "t= g_t * np.ones(x.shape[1])\n",
    "\n",
    "scorenet(x,t,conditioning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditioning = torch.arange(128) % (10 + 26 + 26 + 1)\n",
    "conditioning.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
